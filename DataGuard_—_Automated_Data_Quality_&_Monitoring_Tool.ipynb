{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yE-lwLn06lK",
        "outputId": "0bca6e08-bf31-4a43-bb30-1106cb020a59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quality Report: {'timestamp': '2025-10-19T09:57:25.108559', 'missing_value_ratio': np.float64(0.031746031746031744), 'duplicate_record_ratio': np.float64(0.047619047619047616), 'outlier_ratio_value': 0.010526315789473684, 'status': 'PASS'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3347860158.py:62: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  report[\"timestamp\"] = datetime.utcnow().isoformat()\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# DataGuard â€” Automated Data Quality & Monitoring Tool (Colab ready)\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import json\n",
        "import random\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "# Configuration\n",
        "INPUT_CSV = \"data/input_data.csv\"\n",
        "REPORT_JSON = \"data/quality_report.json\"\n",
        "THRESHOLDS = {\n",
        "    \"missing_value_ratio\": 0.1,\n",
        "    \"duplicate_record_ratio\": 0.05,\n",
        "    \"outlier_zscore\": 3.0\n",
        "}\n",
        "\n",
        "# Ensure directories\n",
        "os.makedirs(os.path.dirname(INPUT_CSV), exist_ok=True)\n",
        "os.makedirs(os.path.dirname(REPORT_JSON), exist_ok=True)\n",
        "\n",
        "# Generate dummy data if not exist\n",
        "if not os.path.exists(INPUT_CSV):\n",
        "    df = pd.DataFrame({\n",
        "        \"id\": range(1, 101),\n",
        "        \"value\": [random.gauss(50,10) for _ in range(100)],\n",
        "        \"status\": [random.choice([\"A\",\"B\",\"C\",\"D\"]) for _ in range(100)]\n",
        "    })\n",
        "    # introduce missing values\n",
        "    df.loc[random.sample(range(100), 10), \"value\"] = None\n",
        "    # duplicate some rows\n",
        "    rows_to_duplicate = df.iloc[random.sample(range(100), 5)]\n",
        "    df = pd.concat([df, rows_to_duplicate], ignore_index=True)\n",
        "    df.to_csv(INPUT_CSV, index=False)\n",
        "\n",
        "def load_data(path):\n",
        "    return pd.read_csv(path)\n",
        "\n",
        "def check_missing(df):\n",
        "    total = df.shape[0] * df.shape[1]\n",
        "    missing = df.isna().sum().sum()\n",
        "    return missing / total\n",
        "\n",
        "def check_duplicates(df):\n",
        "    total = df.shape[0]\n",
        "    dup = df.duplicated().sum()\n",
        "    return dup / total\n",
        "\n",
        "def check_outliers(df, column, z_thresh):\n",
        "    col = df[column].dropna()\n",
        "    mean = col.mean()\n",
        "    std = col.std()\n",
        "    outliers = col[(col - mean).abs() > z_thresh * std]\n",
        "    return len(outliers) / len(col) if len(col) > 0 else 0\n",
        "\n",
        "def run_quality_checks(path):\n",
        "    df = load_data(path)\n",
        "    report = {}\n",
        "    report[\"timestamp\"] = datetime.utcnow().isoformat()\n",
        "    report[\"missing_value_ratio\"] = check_missing(df)\n",
        "    report[\"duplicate_record_ratio\"] = check_duplicates(df)\n",
        "    report[\"outlier_ratio_value\"] = check_outliers(df, \"value\", THRESHOLDS[\"outlier_zscore\"])\n",
        "    report[\"status\"] = \"PASS\"\n",
        "    if (report[\"missing_value_ratio\"] > THRESHOLDS[\"missing_value_ratio\"] or\n",
        "        report[\"duplicate_record_ratio\"] > THRESHOLDS[\"duplicate_record_ratio\"] or\n",
        "        report[\"outlier_ratio_value\"] > 0.10):\n",
        "        report[\"status\"] = \"FAIL\"\n",
        "    with open(REPORT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(report, f, indent=2)\n",
        "    return report\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    report = run_quality_checks(INPUT_CSV)\n",
        "    print(\"Quality Report:\", report)\n"
      ]
    }
  ]
}